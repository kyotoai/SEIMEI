<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>SEIMEI – KyotoAI Documentation</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Tailwind CDN (for static docs this is usually fine) -->
    <script src="https://cdn.tailwindcss.com"></script>

    <style>
      :root {
        --primary: 129 140 248; /* indigo-400 */
        --primary-dark: 79 70 229; /* indigo-600 */
        --bg-dark: 15 23 42; /* slate-900 */
        --bg-darker: 0 0 0;
      }

      body {
        background-color: rgb(var(--bg-dark));
        color: rgb(226, 232, 240);
      }

      ::selection {
        background: rgba(129, 140, 248, 0.35);
      }

      /* Thin scrollbar similar to the docs you pasted */
      .thin-scrollbar::-webkit-scrollbar {
        width: 6px;
        height: 6px;
      }
      .thin-scrollbar::-webkit-scrollbar-thumb {
        background-color: rgba(148, 163, 184, 0.6);
        border-radius: 999px;
      }

      pre code {
        font-variant-ligatures: none;
      }
    </style>
  </head>
  <body class="min-h-screen antialiased">
    <div class="min-h-screen flex bg-slate-950 text-slate-100">
      <!-- SIDEBAR -->
      <aside
        class="hidden lg:flex w-64 flex-col border-r border-slate-800 bg-slate-950/90 backdrop-blur-sm"
      >
        <div class="px-6 py-4 border-b border-slate-800 flex items-center gap-3">
          <div
            class="h-8 w-8 rounded-xl bg-gradient-to-br from-indigo-400 via-purple-500 to-sky-400 flex items-center justify-center text-xs font-bold"
          >
            K
          </div>
          <div class="flex flex-col">
            <span class="text-sm font-semibold tracking-tight">KyotoAI</span>
            <span class="text-xs text-slate-400">SEIMEI Documentation</span>
          </div>
        </div>

        <nav
          class="flex-1 overflow-y-auto thin-scrollbar px-4 py-4 text-sm space-y-6"
        >
          <div>
            <h3 class="text-xs font-semibold text-slate-500 uppercase mb-2">
              GET STARTED
            </h3>
            <ul class="space-y-1">
              <li>
                <a
                  href="#intro"
                  class="block rounded-lg px-2 py-1.5 text-slate-200 bg-slate-900/70 font-medium"
                  >Introduction</a
                >
              </li>
              <li>
                <a
                  href="#quick-start"
                  class="block rounded-lg px-2 py-1.5 text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                  >Quick Start</a
                >
              </li>
            </ul>
          </div>

          <div>
            <h3 class="text-xs font-semibold text-slate-500 uppercase mb-2">
              AGENT USAGE
            </h3>
            <ul class="space-y-1">
              <li>
                <a
                  href="#code-act"
                  class="block rounded-lg px-2 py-1.5 text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                  >Code Act</a
                >
              </li>
              <li>
                <a
                  href="#web-search"
                  class="block rounded-lg px-2 py-1.5 text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                  >Web Search</a
                >
              </li>
              <li>
                <a
                  href="#custom-agent"
                  class="block rounded-lg px-2 py-1.5 text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                  >Custom Agent</a
                >
              </li>
            </ul>
          </div>

          <div>
            <h3 class="text-xs font-semibold text-slate-500 uppercase mb-2">
              OPERATIONS
            </h3>
            <ul class="space-y-1">
              <li>
                <a
                  href="#limits"
                  class="block rounded-lg px-2 py-1.5 text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                  >Rate Limits</a
                >
              </li>
              <li>
                <a
                  href="#pricing"
                  class="block rounded-lg px-2 py-1.5 text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                  >Pricing & Deployment</a
                >
              </li>
            </ul>
          </div>
        </nav>

        <div
          class="border-t border-slate-800 px-4 py-3 text-xs text-slate-500 space-y-1"
        >
          <div class="flex items-center justify-between">
            <span>Docs Version</span>
            <span class="font-mono text-slate-300">v0.1</span>
          </div>
          <div class="flex items-center justify-between">
            <span>Project</span>
            <span class="font-mono text-slate-300">SEIMEI</span>
          </div>
        </div>
      </aside>

      <!-- MAIN CONTENT -->
      <main
        class="flex-1 max-w-5xl mx-auto px-4 sm:px-6 lg:px-12 py-10 lg:py-12"
      >
        <!-- Top breadcrumb / header -->
        <header id="intro" class="mb-8">
          <div class="mb-2 text-sm font-semibold text-indigo-300">
            Get Started
          </div>
          <h1
            class="text-3xl sm:text-4xl font-bold tracking-tight text-slate-50 mb-3"
          >
            SEIMEI – Search-Enhanced Interface for Multi-Expertise Inference
          </h1>
          <p class="text-slate-300 text-base sm:text-lg max-w-3xl">
            SEIMEI is KyotoAI’s agent system. It uses
            <span class="font-semibold">reward-model-based search (RMSearch)</span>
            to guide thousands of reasoning agents, keeping long chains of
            thought accurate and grounded in your data.
          </p>

          <div
            class="mt-4 inline-flex items-center gap-2 rounded-full border border-indigo-500/40 bg-indigo-500/10 px-3 py-1 text-xs text-indigo-200"
          >
            <span class="h-2 w-2 rounded-full bg-emerald-400 animate-pulse"></span>
            <span>Alpha – API stable, internals evolving</span>
          </div>
        </header>

        <section
          class="prose prose-invert max-w-none prose-headings:scroll-mt-24"
        >
          <h2 class="text-xl font-semibold text-slate-50 mb-3">
            What the READMEs highlight
          </h2>
          <p class="text-slate-300">
            This page condenses the two READMEs in the repository
            (<code>README.md</code> and <code>seimei/README.md</code>). Together
            they describe SEIMEI as a search-enhanced orchestrator where RMSearch
            picks the next reasoning step and lightweight agents execute the
            plan.
          </p>
          <ul class="text-slate-300 list-disc list-inside space-y-1.5">
            <li>
              <span class="font-semibold">Reward-model guidance</span> – stay
              close to the process shown in the main README image gallery:
              search a large pool of experts and favor the most promising
              thought chain.
            </li>
            <li>
              <span class="font-semibold">Composable orchestrator</span> – the
              `seimei` class (documented in <code>seimei/README.md</code>)
              loads agents, enforces token limits, and logs every run.
            </li>
            <li>
              <span class="font-semibold">Dataset logging</span> – each run
              writes artifacts under <code>seimei_runs/</code> so you can train
              RMSearch or replay experiments.
            </li>
          </ul>

          <div
            class="mt-5 mb-6 flex gap-3 rounded-2xl border border-sky-400/40 bg-sky-500/10 p-4"
          >
            <div
              class="mt-0.5 h-5 w-5 flex-none rounded-full bg-sky-500/20 flex items-center justify-center"
            >
              <span class="text-sky-300 text-xs font-bold">i</span>
            </div>
            <div class="text-sm text-slate-100 space-y-1.5">
              <p class="font-semibold">Key idea from README.md</p>
              <p class="text-slate-200/90">
                Train a smaller RMSearch model to choose the next branch instead
                of constantly fine-tuning the base LLM. The orchestrator stays
                fast, reusable, and far cheaper to adapt to new domains.
              </p>
            </div>
          </div>

          <h2 class="text-xl font-semibold text-slate-50 mb-3">
            Architecture at a glance
          </h2>
          <p class="text-slate-300">
            Borrowing the "Search the Best Agent" and "The Most Intelligent
            Search Engine" sections from the main README, SEIMEI flows through
            four repeating steps:
          </p>

          <div
            class="mt-4 grid gap-4 sm:grid-cols-2 text-sm text-slate-200/90"
          >
            <div
              class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4"
            >
              <h3 class="text-sm font-semibold mb-1.5">1. Ingest & index</h3>
              <p class="text-slate-300 text-sm">
                Pull papers, repos, experiment logs, or meeting notes into an
                index. Combine your own vector store with the RMSearch training
                data mentioned in the README walkthrough.
              </p>
            </div>
            <div
              class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4"
            >
              <h3 class="text-sm font-semibold mb-1.5">2. Reward rerank</h3>
              <p class="text-slate-300 text-sm">
                RMSearch scores "agent × question" pairs and reasoning states,
                similar to the comparison plots shown in the README. High scorers
                get scheduled next.
              </p>
            </div>
            <div
              class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4"
            >
              <h3 class="text-sm font-semibold mb-1.5">3. Agent execution</h3>
              <p class="text-slate-300 text-sm">
                The orchestrator from <code>seimei/README.md</code> loads
                planners, tool users, and synthesis agents, applying allowlists
                and shared context.
              </p>
            </div>
            <div
              class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4"
            >
              <h3 class="text-sm font-semibold mb-1.5">4. Final response</h3>
              <p class="text-slate-300 text-sm">
                When an agent returns <code>final_output</code>, SEIMEI
                summarizes the reasoning traces, saves logs, and (optionally)
                feeds the run back into the knowledge base.
              </p>
            </div>
          </div>

          <h2 class="mt-8 text-xl font-semibold text-slate-50 mb-3">
            Typical workflow
          </h2>
          <ol class="list-decimal list-inside space-y-1.5 text-slate-300">
            <li>Sync your corpus and agents into a directory.</li>
            <li>
              Train or plug in RMSearch (see the comparison charts in the main
              README).
            </li>
            <li>
              Instantiate the `seimei` orchestrator with the config shown in
              <code>seimei/README.md</code>.
            </li>
            <li>
              Let RMSearch rank instructions/agents on every step, keeping
              reasoning grounded and affordable.
            </li>
            <li>
              Persist the run for later evaluation or dataset generation under
              <code>seimei_runs/</code>.
            </li>
          </ol>
        </section>

        <section id="quick-start" class="mt-10">
          <h2 class="text-xl font-semibold text-slate-50 mb-2">Quick Start</h2>
          <p class="text-slate-300 mb-4">
            Follow the same steps documented in
            <code>README.md</code> and <code>seimei/README.md</code>: install
            the package, export your API keys, and run either the CLI or a small
            Python script. Everything below is a lightly formatted version of
            those instructions.
          </p>

          <div class="grid gap-4 md:grid-cols-2">
            <div
              class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4 text-sm text-slate-200"
            >
              <h3 class="text-sm font-semibold mb-2">
                Install from source (README.md)
              </h3>
              <p class="text-slate-300">
                Clone the repository locally and install it in editable mode so
                the CLI and Python import paths stay in sync with your edits.
              </p>
              <pre
                class="mt-3 rounded-xl border border-slate-800 bg-black/30 p-3 font-mono text-xs thin-scrollbar overflow-x-auto"
              ><code>git clone https://github.com/kyotoai/SEIMEI.git
cd SEIMEI
pip install -e .</code></pre>
              <p class="mt-3 text-slate-400">
                Optional: <code>pip install duckduckgo_search requests</code> to
                enable the web-search agent showcased below.
              </p>
            </div>
            <div
              class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4 text-sm text-slate-200"
            >
              <h3 class="text-sm font-semibold mb-2">
                Set API keys (both READMEs)
              </h3>
              <p class="text-slate-300">
                Export your OpenAI-compatible key (for LLM calls) and the
                KyotoAI key (for RMSearch). The CLI inherits them automatically.
              </p>
              <pre
                class="mt-3 rounded-xl border border-slate-800 bg-black/30 p-3 font-mono text-xs thin-scrollbar overflow-x-auto"
              ><code>export OPENAI_API_KEY="your-openai-api-key"
export KYOTOAI_API_KEY="your-kyotoai-api-key"</code></pre>
              <p class="mt-3 text-slate-400">
                Prefix these commands with <code>set -a</code> in zsh or add them
                to your shell profile if you want them available for every
                session.
              </p>
            </div>
          </div>

          <div
            class="mt-6 rounded-2xl border border-slate-800 bg-slate-900/70 p-4 text-sm text-slate-200"
          >
            <h3 class="text-sm font-semibold mb-2">Example commands</h3>
            <p class="text-slate-300">
              Use the CLI for a fast smoke test or the Python orchestrator for a
              full-featured run. Both snippets are lifted directly from the
              READMEs.
            </p>

            <div
              class="code-group mt-4 rounded-xl border border-slate-800 bg-slate-950/50 overflow-hidden"
              data-code-group
            >
              <div
                class="flex items-center justify-between border-b border-slate-800 px-4 py-2"
              >
                <div class="flex items-center gap-2 text-xs">
                  <button
                    type="button"
                    class="code-tab px-2 py-1 rounded-md bg-slate-800 text-indigo-300 font-medium"
                    data-lang-tab="shell"
                  >
                    Shell
                  </button>
                  <button
                    type="button"
                    class="code-tab px-2 py-1 rounded-md text-slate-400 hover:text-slate-100 hover:bg-slate-800/70"
                    data-lang-tab="python"
                  >
                    Python
                  </button>
                </div>
                <button
                  type="button"
                  class="copy-btn text-[11px] px-2 py-1 rounded-md border border-slate-700 text-slate-300 hover:bg-slate-800/80"
                  data-copy
                >
                  Copy
                </button>
              </div>

              <div
                class="p-4 text-sm font-mono leading-6 text-slate-100 thin-scrollbar overflow-x-auto"
              >
                <pre data-lang="shell">
<code># Start the CLI that mirrors seimei/README.md
seimei

# Sample prompt:
# "Analyze the files inside this folder and explain what SEIMEI is."</code>
                </pre>

                <pre data-lang="python" class="hidden">
<code>import asyncio
from seimei import seimei

async def demo():
    orchestrator = seimei(
        llm_kwargs={"model": "gpt-5-nano"},
        rm_kwargs={"url": "https://kyotoai.net/v1/rmsearch", "agent_routing": False, "knowledge_search": True},
        allow_code_exec=True,
        agent_log_head_lines=1,
        max_tokens_per_question=30000,
    )

    result = await orchestrator(
        messages=[{"role": "user", "content": "Design a 7-day turbulence plan based on my history."}],
        knowledge_config={
            "load_knowledge_path": "seimei_knowledge/knowledge.csv",
        },
    )
    print(result["output"])

asyncio.run(demo())</code>
                </pre>
              </div>
            </div>
          </div>

          <div
            class="mt-6 rounded-2xl border border-slate-800 bg-slate-900/70 p-4 text-sm text-slate-200"
          >
            <h3 class="text-sm font-semibold mb-2">
              Log every run to knowledge (README.md)
            </h3>
            <p class="text-slate-300">
              Set <code>knowledge_config["generate_knowledge"] = True</code>
              to append retrospectives into
              <code>seimei_knowledge/</code>. The helper
              <code>seimei.knowledge.generate_from_runs</code> mirrors the
              snippet in the root README.
            </p>
            <pre
              class="mt-3 rounded-xl border border-slate-800 bg-black/30 p-3 font-mono text-xs thin-scrollbar overflow-x-auto"
            ><code>result = await orchestrator(
    messages=[{"role": "user", "content": "Find ways to speed up the ETL pipeline."}],
    knowledge_config={
        "generate_knowledge": True,
        "save_knowledge_path": "seimei_knowledge/knowledge.csv",
        "knowledge_prompt_path": "seimei/knowledge/prompts/generate_from_runs.md",
        "load_knowledge_path": "seimei_knowledge/knowledge.csv",
    },
)</code></pre>
          </div>
        </section>

        <section id="code-act" class="mt-12">
          <h2 class="text-xl font-semibold text-slate-50 mb-2">
            Code Act agent
          </h2>
          <p class="text-slate-300 mb-3">
            Reproduce the built-in
            <code>seimei/agents/code_act.py</code> example from
            <code>seimei/README.md</code>. It executes whitelisted shell
            commands, streams logs, and can write knowledge after every run.
          </p>
          <ul class="text-slate-300 list-disc list-inside space-y-1.5 mb-4">
            <li>
              Turn on <code>allow_code_exec=True</code> and restrict
              <code>allowed_commands</code> to keep the sandbox tight.
            </li>
            <li>
              Pass a <code>system</code> message if you need stricter execution
              etiquette (e.g., "never run unasked commands").
            </li>
            <li>
              Inspect <code>result["msg_history"][-2]</code> for the agent’s raw
              reply, exactly as depicted in the README snippet.
            </li>
          </ul>
          <div
            class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4 font-mono text-sm text-slate-100 thin-scrollbar overflow-x-auto"
          >
            <pre><code>import asyncio
from seimei import seimei

async def demo_code_act():
    orchestrator = seimei(
        agent_config=[{"file_path": "seimei/agents/code_act.py"}],
        llm_kwargs={"model": "gpt-4o-mini"},
        allow_code_exec=True,
        allowed_commands=["ls", "cat", "python"],
        agent_log_head_lines=1,
        max_tokens_per_question=2000,
    )

    result = await orchestrator(
        messages=[
            {"role": "system", "content": "You are an execution assistant that never runs unasked commands."},
            {"role": "user", "content": "List the repo root and summarize the files."},
        ],
    )
    print(result["msg_history"][-2]["content"])

asyncio.run(demo_code_act())</code></pre>
          </div>
        </section>

        <section id="web-search" class="mt-12">
          <h2 class="text-xl font-semibold text-slate-50 mb-2">
            Web Search agent
          </h2>
          <p class="text-slate-300 mb-3">
            The README also ships a
            <code>seimei/agents/web_search.py</code> demo. Install
            <code>duckduckgo_search</code> (see Quick Start) and use the agent to
            collect quick facts without leaving the orchestrator.
          </p>
          <div
            class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4 font-mono text-sm text-slate-100 thin-scrollbar overflow-x-auto"
          >
            <pre><code>import asyncio
from seimei import seimei

async def demo_web_search():
    orchestrator = seimei(
        agent_config=[{"file_path": "seimei/agents/web_search.py"}],
        llm_kwargs={"model": "gpt-4o-mini"},
        agent_log_head_lines=2,
        max_tokens_per_question=4000,
    )

    result = await orchestrator(
        messages=[
            {"role": "system", "content": "You gather concise search summaries."},
            {"role": "user", "content": "Search for recent applications of perovskite solar cells."},
        ]
    )
    print(result["msg_history"][-2]["content"])

asyncio.run(demo_web_search())</code></pre>
          </div>
        </section>

        <section id="custom-agent" class="mt-12">
          <h2 class="text-xl font-semibold text-slate-50 mb-2">
            Custom agent skeleton
          </h2>
          <p class="text-slate-300 mb-3">
            Extend SEIMEI by following the “Create an agent” guide inside
            <code>seimei/README.md</code>. Drop new files anywhere and add them
            to <code>agent_config</code>.
          </p>
          <div
            class="rounded-2xl border border-slate-800 bg-slate-900/70 p-4 font-mono text-sm text-slate-100 thin-scrollbar overflow-x-auto"
          >
            <pre><code>from seimei import Agent

class prioritise_docs(Agent):
    """Rank documentation chunks that should be read next."""

    description = "Select document chunks relevant to the latest user request."

    async def inference(self, messages, shared_ctx, **kwargs):
        search = shared_ctx.get("search")
        if not search:
            return {"content": "search helper unavailable", "log": {}}

        question = next((m["content"] for m in reversed(messages) if m.get("role") == "user"), "")
        candidates = [{"key": text, "section": name} for name, text in kwargs.get("docs", [])]

        ranked = await search(
            query=question,
            keys=candidates,
            k=3,
            context={"purpose": "doc_ranking"},
        )
        plan = "\n".join(f"- {item['payload']['section']}" for item in ranked if item.get("payload"))
        return {"content": f"Review next:\n{plan}", "log": {"query": question, "sections": ranked}}
</code></pre>
          </div>
          <p class="text-slate-400 text-sm mt-3">
            Use <code>agent_config=[{"dir_path": "my_agents"}]</code> to load
            every Python file in that directory. The shared context exposes the
            RMSearch helper, instruction list, and run-scoped LLM proxy.
          </p>
        </section>

        <!-- LIMITS -->
        <section id="limits" class="mt-10">
          <h2 class="text-xl font-semibold text-slate-50 mb-2">
            Rate limiting & usage units
          </h2>
          <p class="text-slate-300">
            SEIMEI and RMSearch are billed and rate-limited using
            <span class="font-semibold">UTF-8 bytes</span>, not tokens. This
            makes costs predictable across languages and models.
          </p>

          <div
            class="mt-4 rounded-2xl border border-slate-800 bg-slate-900/70 p-4 text-sm text-slate-200"
          >
            <p class="font-semibold mb-2">Per-minute soft limit (example)</p>
            <p class="mb-2">
              Suppose we allow
              <code class="text-indigo-300">2,000,000 bytes/minute</code>
              per API key:
            </p>

            <div
              class="mt-3 rounded-xl border border-slate-800 bg-black/20 p-3 font-mono text-xs thin-scrollbar overflow-x-auto"
            >
              <pre><code>Total bytes for one RMSearch call =
  overhead_bytes
  + len(query.encode("utf-8"))
  + sum(len(doc_i.encode("utf-8")) for each document)</code></pre>
            </div>

            <p class="mt-3 text-slate-300">
              When you exceed the soft limit, requests may still succeed but be
              throttled into a higher-latency mode. For production deployments
              we recommend aggregating queries and using streaming where
              possible.
            </p>
          </div>
        </section>

        <!-- PRICING -->
        <section id="pricing" class="mt-10 mb-16">
          <h2 class="text-xl font-semibold text-slate-50 mb-2">
            Pricing & deployment model
          </h2>
          <p class="text-slate-300 mb-3">
            SEIMEI is designed to work in both open-source and managed modes.
            The exact pricing will depend on your deployment, but a typical
            setup looks like:
          </p>

          <ul class="list-disc list-inside text-slate-300 space-y-1.5">
            <li>
              <span class="font-semibold">Open-source core</span> – the SEIMEI
              orchestration code and RMSearch reference models under an
              Apache-2.0-style license.
            </li>
            <li>
              <span class="font-semibold">Managed API</span> – KyotoAI hosts
              SEIMEI and RMSearch for you with SLAs, monitoring, and scaling.
            </li>
            <li>
              <span class="font-semibold">Custom deployments</span> – on-prem or
              VPC setups for sensitive scientific workloads.
            </li>
          </ul>

          <div
            class="mt-4 flex gap-3 rounded-2xl border border-amber-500/30 bg-amber-500/10 p-4 text-sm"
          >
            <div
              class="mt-0.5 h-5 w-5 flex-none rounded-full bg-amber-400/20 flex items-center justify-center"
            >
              <span class="text-amber-300 text-xs font-bold">!</span>
            </div>
            <div class="space-y-1.5 text-amber-100">
              <p class="font-semibold">Contract note</p>
              <p>
                If you are providing a project-specific search model or SEIMEI
                deployment under a non-exclusive contract, make sure your terms
                explicitly distinguish between:
              </p>
              <ul class="list-disc list-inside text-amber-100/90">
                <li>the trained model weights and interface, and</li>
                <li>any customer-owned data or analysis deliverables.</li>
              </ul>
              <p class="mt-1">
                That way you can open-source SEIMEI and RMSearch while keeping
                customer data private and respecting their usage rights.
              </p>
            </div>
          </div>
        </section>
      </main>
    </div>

    <!-- Minimal JS for tabs + copy buttons -->
    <script>
      document.addEventListener("DOMContentLoaded", () => {
        const groups = document.querySelectorAll("[data-code-group]");

        groups.forEach((group) => {
          const tabs = group.querySelectorAll("[data-lang-tab]");
          const pres = group.querySelectorAll("pre[data-lang]");
          const copyBtn = group.querySelector("[data-copy]");

          if (!tabs.length || !pres.length || !copyBtn) return;

          let activeLang =
            tabs[0].dataset.langTab || pres[0].dataset.lang || "python";

          function setActive(lang) {
            activeLang = lang;
            tabs.forEach((tab) => {
              const isActive = tab.dataset.langTab === lang;
              tab.classList.toggle("bg-slate-800", isActive);
              tab.classList.toggle("text-indigo-300", isActive);
              tab.classList.toggle("font-medium", isActive);
              tab.classList.toggle("text-slate-400", !isActive);
            });
            pres.forEach((pre) => {
              pre.classList.toggle("hidden", pre.dataset.lang !== lang);
            });
          }

          tabs.forEach((tab) => {
            tab.addEventListener("click", () => {
              setActive(tab.dataset.langTab);
            });
          });

          copyBtn.addEventListener("click", async () => {
            const codeEl = group.querySelector(
              `pre[data-lang="${activeLang}"] code`
            );
            if (!codeEl) return;

            const text = codeEl.textContent || "";
            try {
              await navigator.clipboard.writeText(text);
              const old = copyBtn.textContent;
              copyBtn.textContent = "Copied";
              setTimeout(() => {
                copyBtn.textContent = old;
              }, 1200);
            } catch (e) {
              console.error("copy failed", e);
            }
          });

          // Initialize
          setActive(activeLang);
        });
      });
    </script>
  </body>
</html>
